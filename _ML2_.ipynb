{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = make_regression(n_samples=1000 , n_features=3 , noise=10 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[np.ones(X.shape[0]), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(len(y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(X, y, weights):\n",
    "    \n",
    "# # Example data\n",
    "# X = np.array([[1, 2], [3, 4], [5, 6]])  \n",
    "# y = np.array([5, 11, 17])              \n",
    "# weights = np.array([1, 1])             \n",
    "\n",
    "    #  Calculate predictions by multiplying inputs (X) with weights:)\n",
    "    predictions = X.dot(weights)    #predictions=[1⋅1+2⋅1,3⋅1+4⋅1,5⋅1+6⋅1]=[3,7,11]\n",
    "    \n",
    "    #  Calculate the errors (difference between predictions and actual values):)\n",
    "    errors = predictions - y  #errors=[3−5,7−11,11−17]=[−2,−4,−6]\n",
    "    \n",
    "    # Calculate Mean Squared Error (MSE):)\n",
    "    mse = np.mean(errors ** 2)   #mse=error **2/the number of samples  \n",
    "    \n",
    "    #  Divide by 2 to match the gradient calculation format:)\n",
    "    loss = mse / 2  \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, num_iterations , freq_print):\n",
    "    alpha = 0.001\n",
    "    W = np.random.randn(X.shape[1], 1)\n",
    "    for i in range(num_iterations) :    \n",
    "        yhat = X.dot(W)\n",
    "        error = yhat - y\n",
    "        gradient = X.T.dot(error)\n",
    "        W = W - alpha * gradient / len(X)\n",
    "        if i % freq_print == 0:\n",
    "            print(calculate_loss(X , y , W))\n",
    "        \n",
    "        \n",
    "    return W             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8312.655351815809\n",
      "1221.2065884941326\n",
      "229.73373299063024\n",
      "79.16097386019601\n",
      "54.43521626187781\n",
      "50.08818622723116\n",
      "49.28080884222707\n",
      "49.12457542245187\n",
      "49.09345644672667\n",
      "49.087135838617215\n"
     ]
    }
   ],
   "source": [
    "W = gradient_descent(X_test , y_test , 10000 , 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6079116 ],\n",
       "       [98.19389642],\n",
       "       [81.983694  ],\n",
       "       [25.92508874]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To test the gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function give the most efficient weight and I print the loss for this weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_weight(X, y):\n",
    "    X_transpose = X.T\n",
    "    W = np.linalg.inv(X_transpose @ X) @ X_transpose @ y\n",
    "    \n",
    "    \n",
    "    return W\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print the loss of the most efficient weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.08549457182744\n"
     ]
    }
   ],
   "source": [
    "print(calculate_loss(X_test,y_test,least_weight(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print the loss of Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.08583601163943\n"
     ]
    }
   ],
   "source": [
    "print(calculate_loss(X_test,y_test,W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The efficient weights loss is : 49.08549457182744\n",
    "#### The gradient descent loss is: 49.08583601163943\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the output for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, X):\n",
    "    return X.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(W, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = np.concatenate((predictions.reshape(len(predictions), 1), y_test), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -74.848,  -82.293],\n",
       "       [ 112.993,  104.808],\n",
       "       [  51.101,   55.153],\n",
       "       [ 180.673,  175.842],\n",
       "       [ -22.549,  -12.822],\n",
       "       [-162.556, -158.697],\n",
       "       [ 134.344,  117.792],\n",
       "       [  69.208,   64.592],\n",
       "       [ 231.856,  236.283],\n",
       "       [-112.752, -109.113],\n",
       "       [-106.859, -103.8  ],\n",
       "       [ 118.704,  114.629],\n",
       "       [  31.358,   31.569],\n",
       "       [ -15.916,    2.217],\n",
       "       [  38.189,   43.259],\n",
       "       [ -49.342,  -45.865],\n",
       "       [-190.627, -181.071],\n",
       "       [  61.96 ,   75.81 ],\n",
       "       [  -7.789,   -6.023],\n",
       "       [  43.73 ,   26.268],\n",
       "       [ 102.933,  101.897],\n",
       "       [  38.603,   44.527],\n",
       "       [-127.62 , -125.496],\n",
       "       [  15.838,   26.333],\n",
       "       [-171.955, -173.389],\n",
       "       [  92.482,   77.165],\n",
       "       [   3.043,   -4.217],\n",
       "       [ -72.397,  -78.773],\n",
       "       [ -64.476,  -75.655],\n",
       "       [ -48.47 ,  -40.12 ],\n",
       "       [ 135.678,  128.33 ],\n",
       "       [ -56.544,  -49.205],\n",
       "       [  77.807,   77.515],\n",
       "       [-300.458, -308.578],\n",
       "       [  35.712,   34.249],\n",
       "       [  -9.517,   -2.048],\n",
       "       [ -94.27 ,  -99.682],\n",
       "       [ 192.616,  206.361],\n",
       "       [ -92.854, -103.339],\n",
       "       [ 358.478,  350.629],\n",
       "       [  56.437,   67.598],\n",
       "       [  93.762,  100.791],\n",
       "       [ -74.24 ,  -89.839],\n",
       "       [  78.933,   90.731],\n",
       "       [  90.027,   86.137],\n",
       "       [ 159.699,  150.428],\n",
       "       [ -53.117,  -70.29 ],\n",
       "       [  63.438,   54.236],\n",
       "       [-109.123, -114.251],\n",
       "       [  52.537,   73.582],\n",
       "       [ 202.634,  196.237],\n",
       "       [ -28.243,  -17.861],\n",
       "       [ -84.589,  -86.904],\n",
       "       [ 198.204,  212.167],\n",
       "       [ -59.028,  -49.316],\n",
       "       [-167.51 , -149.769],\n",
       "       [ -38.718,  -41.334],\n",
       "       [-102.41 , -105.439],\n",
       "       [  -0.142,  -10.391],\n",
       "       [ 195.962,  194.903],\n",
       "       [-113.863, -112.983],\n",
       "       [-110.182,  -93.565],\n",
       "       [ -56.784,  -60.848],\n",
       "       [ 175.559,  167.98 ],\n",
       "       [  66.478,   74.455],\n",
       "       [ 308.1  ,  295.242],\n",
       "       [  37.731,   48.929],\n",
       "       [ 146.474,  148.132],\n",
       "       [-105.557, -107.322],\n",
       "       [ -37.715,  -24.073],\n",
       "       [ -90.848, -107.26 ],\n",
       "       [ 176.68 ,  179.063],\n",
       "       [ 221.887,  226.6  ],\n",
       "       [-170.002, -169.755],\n",
       "       [ -28.987,  -47.042],\n",
       "       [ -49.651,  -36.567],\n",
       "       [ 131.357,  135.242],\n",
       "       [ 259.944,  264.076],\n",
       "       [  -1.767,    4.987],\n",
       "       [  23.256,   36.113],\n",
       "       [-190.157, -199.025],\n",
       "       [ 266.15 ,  282.523],\n",
       "       [ -44.286,  -41.417],\n",
       "       [  -7.858,  -14.176],\n",
       "       [   0.976,   -4.665],\n",
       "       [ 118.017,  134.491],\n",
       "       [-112.933, -125.147],\n",
       "       [-153.366, -148.448],\n",
       "       [ 314.345,  313.186],\n",
       "       [   8.931,   13.527],\n",
       "       [  -9.238,    3.957],\n",
       "       [ -98.873, -109.048],\n",
       "       [  62.45 ,   74.096],\n",
       "       [-154.133, -162.116],\n",
       "       [-103.635,  -95.39 ],\n",
       "       [ 194.264,  188.281],\n",
       "       [-101.989,  -90.486],\n",
       "       [ -31.549,  -42.776],\n",
       "       [  51.652,   53.415],\n",
       "       [  37.508,   36.779],\n",
       "       [  55.415,   57.271],\n",
       "       [  77.198,   73.582],\n",
       "       [  84.392,   77.377],\n",
       "       [ 203.719,  204.786],\n",
       "       [   6.936,   -0.331],\n",
       "       [ -35.116,  -27.318],\n",
       "       [ 225.899,  223.525],\n",
       "       [-163.973, -164.77 ],\n",
       "       [ 225.6  ,  235.829],\n",
       "       [ -34.805,  -44.255],\n",
       "       [ 129.939,  127.911],\n",
       "       [ 156.483,  162.896],\n",
       "       [  -5.017,   -5.668],\n",
       "       [  16.205,   16.558],\n",
       "       [ -36.797,  -34.466],\n",
       "       [ 202.378,  225.739],\n",
       "       [ -86.629,  -97.164],\n",
       "       [ -78.655,  -82.697],\n",
       "       [ -19.378,   -8.851],\n",
       "       [  25.866,   15.301],\n",
       "       [ -95.441, -119.383],\n",
       "       [ -58.614,  -53.688],\n",
       "       [ 255.408,  254.082],\n",
       "       [  62.473,   49.708],\n",
       "       [ 281.169,  285.921],\n",
       "       [-140.72 , -167.593],\n",
       "       [-170.071, -167.283],\n",
       "       [ -88.693,  -82.391],\n",
       "       [-208.13 , -205.84 ],\n",
       "       [ 181.252,  176.881],\n",
       "       [ 157.602,  166.266],\n",
       "       [-105.421, -112.637],\n",
       "       [ -90.213,  -99.698],\n",
       "       [  54.108,   40.84 ],\n",
       "       [ 189.91 ,  198.909],\n",
       "       [  99.969,  101.619],\n",
       "       [ -70.551,  -75.221],\n",
       "       [ -10.436,  -14.273],\n",
       "       [ -35.989,  -27.111],\n",
       "       [  13.531,   28.982],\n",
       "       [  15.511,   21.388],\n",
       "       [  89.544,   85.164],\n",
       "       [-166.381, -154.917],\n",
       "       [   0.121,   -5.342],\n",
       "       [-144.355, -139.44 ],\n",
       "       [  -2.426,   11.976],\n",
       "       [   2.976,   -1.286],\n",
       "       [  81.69 ,   77.506],\n",
       "       [  17.306,   13.542],\n",
       "       [ -99.303,  -93.695],\n",
       "       [ -34.512,  -48.731],\n",
       "       [  23.66 ,   30.043],\n",
       "       [-111.479, -119.387],\n",
       "       [ -39.2  ,  -17.423],\n",
       "       [  53.936,   58.611],\n",
       "       [-132.979, -133.057],\n",
       "       [-216.922, -203.672],\n",
       "       [ -22.197,  -28.966],\n",
       "       [ 214.886,  219.731],\n",
       "       [ 142.902,  121.264],\n",
       "       [ 260.175,  244.267],\n",
       "       [ 132.808,  130.678],\n",
       "       [  40.983,   23.542],\n",
       "       [  -5.124,   18.598],\n",
       "       [ 128.382,  131.618],\n",
       "       [ 197.108,  215.092],\n",
       "       [ -99.45 ,  -93.851],\n",
       "       [-197.379, -201.339],\n",
       "       [-192.212, -191.044],\n",
       "       [  74.703,   60.497],\n",
       "       [ 195.288,  210.397],\n",
       "       [ 262.49 ,  255.613],\n",
       "       [ 133.947,  113.687],\n",
       "       [ 369.683,  366.387],\n",
       "       [-106.505,  -82.622],\n",
       "       [ 157.562,  159.175],\n",
       "       [  55.15 ,   56.686],\n",
       "       [  59.66 ,   67.394],\n",
       "       [   7.179,   10.105],\n",
       "       [-188.374, -177.714],\n",
       "       [-236.697, -251.983],\n",
       "       [  88.928,   81.227],\n",
       "       [  86.882,   84.537],\n",
       "       [  54.303,   45.374],\n",
       "       [   5.661,   -4.091],\n",
       "       [-137.804, -129.418],\n",
       "       [-115.033, -115.253],\n",
       "       [  30.155,   34.091],\n",
       "       [ 144.086,  131.001],\n",
       "       [  34.709,   29.394],\n",
       "       [ -66.985,  -60.926],\n",
       "       [ -15.154,   -5.576],\n",
       "       [-173.518, -190.4  ],\n",
       "       [  53.888,   57.717],\n",
       "       [ 145.808,  135.938],\n",
       "       [  24.079,   22.019],\n",
       "       [  56.926,   55.54 ],\n",
       "       [ 106.609,   87.681],\n",
       "       [  65.389,   70.224],\n",
       "       [  57.226,   48.221]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3 ,suppress=True)\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the performance of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, y_pred):\n",
    "    mse = (y - y_pred) ** 2\n",
    "    return np.mean(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(98.17167202327886)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y, y_pred):\n",
    "    mae = np.abs(y - y_pred)\n",
    "    return np.mean(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(8.058159173599313)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
